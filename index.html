<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dejavu: Post‑Deployment Learning for Embodied Agents via Experience Feedback</title>
  <meta name="description" content="ICLR 2026 under review. Dejavu (EFN): a post-deployment learning framework that augments frozen VLA policies with an Experience Feedback Network.">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&display=swap" rel="stylesheet">
  <!-- Bulma (used by nerfies.github.io template) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <!-- Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.4/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
  <style>
    :root { --brand:#4F46E5; --soft:#EEF2FF; }
    html, body { font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol"; }
    .hero.is-light { background: linear-gradient(180deg, var(--soft), white); }
    .publication-title { font-weight: 800; letter-spacing: -0.02em; }
    .author-block a { color:#363636; text-decoration: underline dotted #bdbdbd; }
    .teaser { border-radius: 12px; box-shadow: 0 6px 32px rgba(0,0,0,0.08); }
    .btn-row a.button { margin: 6px 8px 0 0; }
    .section-title { font-weight: 700; font-size: 1.6rem; letter-spacing:-0.01em; }
    .figure { text-align:center; }
    .figure img { border-radius: 12px; box-shadow: 0 6px 28px rgba(0,0,0,0.08); }
    code.bibtex { white-space: pre; display:block; padding:1rem; background:#0f172a; color:#e5e7eb; border-radius:12px; overflow:auto; }
    .tag.is-venue { background: #E0E7FF; color:#1e1b4b; border-radius:999px; }
    .footer { background: #fafafa; }
    .card .teaser {
      width: 100%;
      border-radius: 10px;
      box-shadow: 0 6px 24px rgba(0,0,0,.06);
      display: block;
      margin-top: .5rem;
    }
    .card ol { padding-left: 1.2rem; }
    .card .content { margin-bottom: .5rem; }
  </style>
</head>


<script>
(function () {
  const videos = Array.from(document.querySelectorAll('video.auto-poster'));
  if (!videos.length) return;

  function capturePosterFor(v) {
    if (!v.videoWidth || !v.videoHeight) return;
    const canvas = document.createElement('canvas');
    canvas.width = v.videoWidth;
    canvas.height = v.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(v, 0, 0, canvas.width, canvas.height);
    v.setAttribute('poster', canvas.toDataURL('image/png'));
    // 回到起点，避免停留在 0.1s
    v.pause();
    v.currentTime = 0;
  }

  function tryCapture(v) {
    const seekTo = Math.min(0.1, (v.duration || 1) - 0.1);
    const onSeeked = () => { v.removeEventListener('seeked', onSeeked); capturePosterFor(v); };
    v.addEventListener('seeked', onSeeked, { once: true });
    try { v.currentTime = seekTo; } catch (e) { /* 某些浏览器需等 meta/data 事件后再试 */ }
  }

  videos.forEach(v => {
    if (v.readyState >= 2) {
      tryCapture(v);
    } else {
      v.addEventListener('loadedmetadata', () => tryCapture(v), { once: true });
      v.addEventListener('loadeddata', () => tryCapture(v), { once: true });
    }
  });
})();
</script>

<body>
  <!-- Hero -->
  <section class="hero is-light">
    <div class="hero-body">
      <div class="container">
        <div class="has-text-centered">
          <h1 class="title is-2 publication-title">Dejavu: Post‑Deployment Learning for Embodied Agents<br>via Experience Feedback</h1>
          <p class="subtitle is-5">
            <span class="tag is-venue is-medium">ICLR 2026 — under review</span>
          </p>
          <p class="author-block">
            <em>Anonymous authors</em>
          </p>
          <p class="btn-row">
            <a class="button is-link is-light" href="assets/dejavu.pdf" target="_blank"><span class="icon"><i class="ai ai-arxiv"></i></span><span>Paper (PDF)</span></a>
            <a class="button is-link is-light" href="assets/dejavu_efn.zip" target="_blank"><span class="icon"><i class="fa-solid fa-globe"></i></span><span>Code</span></a>
            <a class="button is-link is-light" href="#bibtex"><span class="icon"><i class="fa-solid fa-quote-right"></i></span><span>BibTeX</span></a>
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser -->
  <section class="section">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-10">
          <figure class="image is-16by9 teaser">
            <!-- Replace with your real teaser image or video poster -->
            <img src="assets/teaser.png" alt="EFN augments a frozen VLA with retrieved experience trajectories and residual action corrections.">
          </figure>
          <p class="has-text-grey is-size-6 has-text-centered" style="margin-top:.5rem;">
            Figure 1. A frozen VLA is augmented by an <strong>Experience Feedback Network (EFN)</strong> that retrieves task‑relevant trajectories,
            predicts a residual correction, and steers the next observation toward the retrieved successor frame.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Abstract -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Abstract</h2>
      <div class="content is-size-5">
        <p>
          We present <strong>Dejavu</strong>, a general post‑deployment learning framework that augments a frozen Vision‑Language‑Action (VLA) policy
          with an <em>Experience Feedback Network (EFN)</em> and a live <em>experience bank</em>. EFN retrieves a contextually successful prior step
          and conditions action prediction on this guidance by outputting a residual correction that refines the base policy’s action.
          EFN is optimized with reinforcement learning using a dense, similarity‑based reward that compares the realized next observation
          to the next observation in the retrieved trajectory. During deployment, the agent continually appends successful rollouts to its
          memory, enabling measurable improvement without modifying the backbone weights.
        </p>
      </div>
      <div class="buttons btn-row">
        <a class="button is-link" href="assets/dejavu.pdf" target="_blank"><span class="icon"><i class="fa-solid fa-file-pdf"></i></span><span>Read the paper</span></a>
      </div>
    </div>
  </section>

  <!-- Links -->
  <!-- <section class="section">
    <div class="container">
      <h2 class="section-title">Resources</h2>
      <div class="buttons btn-row">
        <a class="button is-primary" href="assets/dejavu.pdf" target="_blank"><span class="icon"><i class="fa-solid fa-file-pdf"></i></span><span>Paper (PDF)</span></a>
        <a class="button is-primary is-light" href="https://dejavu2025.github.io/" target="_blank"><span class="icon"><i class="fa-solid fa-globe"></i></span><span>Demo</span></a>
        <a class="button is-primary is-light" href="assets/poster.pdf" target="_blank"><span class="icon"><i class="fa-solid fa-image"></i></span><span>Poster</span></a>
        <a class="button is-primary is-light" href="assets/slides.pdf" target="_blank"><span class="icon"><i class="fa-solid fa-person-chalkboard"></i></span><span>Slides</span></a>
        <a class="button is-primary is-light" href="#bibtex"><span class="icon"><i class="fa-solid fa-quote-right"></i></span><span>BibTeX</span></a>
      </div>
    </div>
  </section> -->

  <section class="section">
    <div class="container">
      <h2 class="section-title">Paper</h2>
        <div class="content has-text-centered">
          <iframe src="assets/dejavu.pdf#view=FitH" style="width:100%; height:600px; border:1px solid #eee; border-radius: 8px;"></iframe>
          <p class="has-text-grey is-size-7" style="margin-top: .5rem;">If the preview does not load, use the PDF button above.</p>
        </div>
    </div>
  </section>


  <!-- Method -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Method Overview</h2>
      <div class="content">
        <p>
          An <strong>experience</strong> is defined as a synchronized trajectory of vision, language, and action. At each step, EFN retrieves a
          task‑filtered candidate from the bank using language‑conditioned visual similarity, then predicts a <em>residual action</em> that is
          added to the base VLA output. A dense semantic reward encourages the next observation to resemble the successor frame from
          the retrieved experience while regularizing residual magnitude and discouraging idling. We train EFN with <em>Soft Actor–Critic</em>
          (SAC) and deploy with deterministic residual corrections.
        </p>
      </div>
      <div class="columns is-multiline">
        <div class="column is-6">
          <div class="box figure">
            <img src="assets/train.png" alt="Training pipeline: retrieval + residual policy learning with similarity rewards.">
            <p class="has-text-grey is-size-7" style="margin-top:.5rem;">Training: retrieve, correct, and optimize with dense similarity rewards.</p>
          </div>
        </div>
        <div class="column is-6">
          <div class="box figure">
            <img src="assets/test.png" alt="Inference pipeline: instruction‑filtered retrieval and online experience growth.">
            <p class="has-text-grey is-size-7" style="margin-top:.5rem;">Inference: instruction‑filtered retrieval and online experience growth.</p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <!-- Results -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Results</h2>
      <div class="content">
        <p>
          On <em>LIBERO</em> simulation and a real‑world <em>AgiBot‑G1</em> platform, EFN consistently increases success rate and reduces steps across
          VLA backbones (OpenVLA, UniVLA), with further gains from larger experience banks. Improvements are most pronounced on
          long‑horizon tasks, indicating recall‑guided residuals effectively truncate redundant behavior.
        </p>
      </div>
        <div class="box figure">
            <img src="assets/tab1.png" alt="LIBERO results">
            <p class="has-text-grey is-size-7" style="margin-top:.5rem;">LIBERO: Deployment performance with and without EFN.</p>
        </div>
        <div class="box figure">
            <img src="assets/tab2.png" alt="Real robot results">
            <p class="has-text-grey is-size-7" style="margin-top:.5rem;">Real‑world: AgiBot‑G1 with GO‑1 across three tasks.</p>
        </div>
    </div>
  </section>

  <!-- Paper teaser / video (optional) -->
<section class="section" id="demos">
  <div class="container">
    <h2 class="section-title">Demos (1 × speed)</h2>

    <div class="columns is-multiline">

      <!-- AddGoods - Trial A -->
      <div class="column is-12">
        <div class="card">
          <header class="card-header">
            <p class="card-header-title">
              <span class="tag is-link is-light" style="margin-right:.5rem;">Task</span> AddGoods · Trial A
            </p>
          </header>
          <div class="card-content">
            <p class="content">
              <strong>Description:</strong> Move the topmost milk can from a vertical stack to the shelf one level above.
            </p>
            <ol class="content" style="margin-top:-.5rem;">
              <li>Grasp the top milk can with the <em>right</em> arm.</li>
              <li>Lift and move to the upper shelf.</li>
              <li>Place the can at the target position.</li>
              <li>Release the right-arm gripper.</li>
            </ol>
            <video class="teaser auto-poster" preload="metadata" controls playsinline crossorigin="anonymous">
              <source src="assets/addgoods1.mp4" type='video/mp4; codecs="avc1.64001f, mp4a.40.2"'>
              <!-- <source src="assets/addgoods1.webm" type="video/webm"> -->
              Your browser does not support inline video.
              <a href="assets/addgoods1.mp4" download>Download MP4</a>.
            </video>
          </div>
        </div>
      </div>

      <!-- AddGoods - Trial B -->
      <div class="column is-12">
        <div class="card">
          <header class="card-header">
            <p class="card-header-title">
              <span class="tag is-link is-light" style="margin-right:.5rem;">Task</span> AddGoods · Trial B
            </p>
          </header>
          <div class="card-content">
            <p class="content">
              <strong>Description:</strong> Move a pen holder that is stacked on a tissue pack to the shelf one level above.
            </p>
            <ol class="content" style="margin-top:-.5rem;">
              <li>Grasp the pen holder from the top of the tissue pack with the <em>right</em> arm.</li>
              <li>Lift and move to the upper shelf.</li>
              <li>Place the pen holder at the target position.</li>
              <li>Release the right-arm gripper.</li>
            </ol>
            <video class="teaser auto-poster" preload="metadata" controls playsinline crossorigin="anonymous">
              <source src="assets/addgoods2.mp4" type='video/mp4; codecs="avc1.64001f, mp4a.40.2"'>
              <!-- <source src="assets/addgoods2.webm" type="video/webm"> -->
              Your browser does not support inline video.
              <a href="assets/addgoods2.mp4" download>Download MP4</a>.
            </video>
          </div>
        </div>
      </div>

      <!-- PutBottle -->
      <div class="column is-12">
        <div class="card">
          <header class="card-header">
            <p class="card-header-title">
              <span class="tag is-link is-light" style="margin-right:.5rem;">Task</span> PutBottle
            </p>
          </header>
          <div class="card-content">
            <p class="content">
              <strong>Description:</strong> Grasp a drink bottle from the shelf with the right arm, place it next to similar items on the shelf, and release the gripper.
            </p>
            <ol class="content" style="margin-top:-.5rem;">
              <li>Grasp the drink bottle from the shelf with the <em>right</em> arm.</li>
              <li>Move to the section with similar items.</li>
              <li>Place the bottle next to similar items.</li>
              <li>Release the right-arm gripper.</li>
            </ol>
            <video class="teaser auto-poster" preload="metadata" controls playsinline crossorigin="anonymous">
              <source src="assets/putbottle.mp4" type='video/mp4; codecs="avc1.64001f, mp4a.40.2"'>
              <!-- <source src="assets/putbottle.webm" type="video/webm"> -->
              Your browser does not support inline video.
              <a href="assets/putbottle.mp4" download>Download MP4</a>.
            </video>
          </div>
        </div>
      </div>

      <!-- SortItem -->
      <div class="column is-12">
        <div class="card">
          <header class="card-header">
            <p class="card-header-title">
              <span class="tag is-link is-light" style="margin-right:.5rem;">Task</span> SortItem
            </p>
          </header>
          <div class="card-content">
            <p class="content">
              <strong>Description:</strong> Pick up a drink bottle from a small tabletop with the right arm and place it on the shelf.
            </p>
            <ol class="content" style="margin-top:-.5rem;">
              <li>Pick up a drink bottle from the tabletop with the <em>right</em> arm.</li>
              <li>Move to the target shelf position.</li>
              <li>Place the bottle on the shelf.</li>
              <li>Release the right-arm gripper.</li>
            </ol>
            <video class="teaser auto-poster" preload="metadata" controls playsinline crossorigin="anonymous">
              <source src="assets/sortitem.mp4" type='video/mp4; codecs="avc1.64001f, mp4a.40.2"'>
              <!-- <source src="assets/sortitem.webm" type="video/webm"> -->
              Your browser does not support inline video.
              <a href="assets/sortitem.mp4" download>Download MP4</a>.
            </video>
          </div>
        </div>
      </div>

    </div>
  </div>
</section>



  <!-- Citation -->
  <section class="section" id="bibtex">
    <div class="container">
      <h2 class="section-title">BibTeX</h2>
      <code class="bibtex">@inproceedings{dejavu_iclr2026,
  title     = {Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback},
  author    = {Anonymous},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2026},
  note      = {under double-blind review},
  url       = {https://dejavu2025.github.io/}
}</code>
    </div>
  </section>

  <!-- Acknowledgements -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Acknowledgements</h2>
      <p class="content">
        This website follows the structure of the <em>nerfies.github.io</em> academic project template.
      </p>
    </div>
  </section>

  <footer class="footer">
    <div class="content has-text-centered">
      <p>
        <strong>Dejavu (EFN)</strong> — ICLR 2026 (under review). Site template inspired by <em>nerfies.github.io</em>.
      </p>
    </div>
  </footer>
</body>
</html>
