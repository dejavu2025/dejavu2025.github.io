<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dejavu: Towards Experience Feedback Learning for Embodied Intelligence</title>
  <meta name="description" content="CVPR 2026 under review. Dejavu (EFN): a post-deployment learning framework that augments frozen VLA policies with an Experience Feedback Network.">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&display=swap" rel="stylesheet">
  <!-- Bulma (used by nerfies.github.io template) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <!-- Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.4/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
  <style>
    :root { --brand:#4F46E5; --soft:#EEF2FF; }
    html, body { font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol"; }
    .hero.is-light { background: linear-gradient(180deg, var(--soft), white); }
    .publication-title { font-weight: 800; letter-spacing: -0.02em; }
    .author-block a { color:#363636; text-decoration: underline dotted #bdbdbd; }
    .teaser { border-radius: 12px; box-shadow: 0 6px 32px rgba(0,0,0,0.08); }
    .btn-row a.button { margin: 6px 8px 0 0; }
    .section-title { font-weight: 700; font-size: 1.6rem; letter-spacing:-0.01em; }
    .figure { text-align:center; }
    .figure img { border-radius: 12px; box-shadow: 0 6px 28px rgba(0,0,0,0.08); }
    code.bibtex { white-space: pre; display:block; padding:1rem; background:#0f172a; color:#e5e7eb; border-radius:12px; overflow:auto; }
    .tag.is-venue { background: #E0E7FF; color:#1e1b4b; border-radius:999px; }
    .footer { background: #fafafa; }
    .card .teaser {
      width: 100%;
      border-radius: 10px;
      box-shadow: 0 6px 24px rgba(0,0,0,.06);
      display: block;
      margin-top: .5rem;
    }
    .card ol { padding-left: 1.2rem; }
    .card .content { margin-bottom: .5rem; }
    .authors{
      margin-top: .75rem;
      text-align: center;         /* 常见学术主页风格 */
    }

    .author-line{
      margin: .1rem 0;
      line-height: 1.45;
      font-size: 1.05rem;
      font-weight: 600;
      color: #2b2b2b;
    }

    .affiliation{
      margin-top: .35rem;
      font-size: .95rem;
      color: #666;
      font-weight: 500;
    }

    .authors a{
      color:#2b2b2b;
      text-decoration: none;
      border-bottom: 1px dotted #bdbdbd;
      padding-bottom: 1px;
    }
    .authors a:hover{
      border-bottom-style: solid;
    }

  </style>
</head>


<script>
(function () {
  const videos = Array.from(document.querySelectorAll('video.auto-poster'));
  if (!videos.length) return;

  function capturePosterFor(v) {
    if (!v.videoWidth || !v.videoHeight) return;
    const canvas = document.createElement('canvas');
    canvas.width = v.videoWidth;
    canvas.height = v.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(v, 0, 0, canvas.width, canvas.height);
    v.setAttribute('poster', canvas.toDataURL('image/png'));
    // 回到起点，避免停留在 0.1s
    v.pause();
    v.currentTime = 0;
  }

  function tryCapture(v) {
    const seekTo = Math.min(0.1, (v.duration || 1) - 0.1);
    const onSeeked = () => { v.removeEventListener('seeked', onSeeked); capturePosterFor(v); };
    v.addEventListener('seeked', onSeeked, { once: true });
    try { v.currentTime = seekTo; } catch (e) { /* 某些浏览器需等 meta/data 事件后再试 */ }
  }

  videos.forEach(v => {
    if (v.readyState >= 2) {
      tryCapture(v);
    } else {
      v.addEventListener('loadedmetadata', () => tryCapture(v), { once: true });
      v.addEventListener('loadeddata', () => tryCapture(v), { once: true });
    }
  });
})();
</script>

<body>
  <!-- Hero -->
  <section class="hero is-light">
    <div class="hero-body">
      <div class="container">
        <div class="has-text-centered">
          <h1 class="title is-2 publication-title">Dejavu: Towards Experience Feedback Learning for Embodied Intelligence</h1>
          <!-- <p class="subtitle is-5">
            <span class="tag is-venue is-medium">CVPR 2026 — under review</span>
          </p> -->
        <div class="authors">
          <div class="author-line">
            Shaokai Wu, Yanbiao Ji, Qiuchang Li, Zhiyi Zhang, Qichen He,
          </div>
          <div class="author-line">
            Wenyuan Xie, Guodong Zhang, Bayram Bayramli, Yue Ding, Hongtao Lu
          </div>
          <div class="affiliation">
            School of Computer Science, Shanghai Jiao Tong University
          </div>
        </div>
          <p class="btn-row">
            <a class="button is-link is-light" href="assets/dejavu.pdf" target="_blank"><span class="icon"><i class="ai ai-arxiv"></i></span><span>Paper (PDF)</span></a>
            <a class="button is-link is-light" href="assets/code.zip" target="_blank"><span class="icon"><i class="fa-solid fa-globe"></i></span><span>Code</span></a>
            <a class="button is-link is-light" href="#bibtex"><span class="icon"><i class="fa-solid fa-quote-right"></i></span><span>BibTeX</span></a>
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser -->
  <section class="section">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-10">
          <figure class="image is-16by9 teaser">
            <!-- Replace with your real teaser image or video poster -->
            <img src="assets/teaser.png" alt="EFN augments a frozen VLA with retrieved experience trajectories and residual action corrections.">
          </figure>
          <p class="has-text-grey is-size-6 has-text-centered" style="margin-top:.5rem;">
            Figure 1. A frozen VLA is augmented by an <strong>Experience Feedback Network (EFN)</strong> that retrieves task‑relevant trajectories,
            predicts a residual correction, and steers the next observation toward the retrieved successor frame.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Abstract -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Abstract</h2>
      <div class="content is-size-5">
        <p>
          We present <strong>Dejavu</strong>, a general post‑deployment learning framework that augments a frozen Vision‑Language‑Action (VLA) policy
          with an <em>Experience Feedback Network (EFN)</em> and a live <em>experience bank</em>. EFN retrieves a contextually successful prior step
          and conditions action prediction on this guidance by outputting a residual correction that refines the base policy’s action.
          EFN is optimized with reinforcement learning using a dense, similarity‑based reward that compares the realized next observation
          to the next observation in the retrieved trajectory. During deployment, the agent continually appends successful rollouts to its
          memory, enabling measurable improvement without modifying the backbone weights.
        </p>
      </div>
      <div class="buttons btn-row">
        <a class="button is-link" href="assets/dejavu.pdf" target="_blank"><span class="icon"><i class="fa-solid fa-file-pdf"></i></span><span>Read the paper</span></a>
      </div>
    </div>
  </section>

  <!-- Links -->
  <!-- <section class="section">
    <div class="container">
      <h2 class="section-title">Resources</h2>
      <div class="buttons btn-row">
        <a class="button is-primary" href="assets/dejavu.pdf" target="_blank"><span class="icon"><i class="fa-solid fa-file-pdf"></i></span><span>Paper (PDF)</span></a>
        <a class="button is-primary is-light" href="https://dejavu2025.github.io/" target="_blank"><span class="icon"><i class="fa-solid fa-globe"></i></span><span>Demo</span></a>
        <a class="button is-primary is-light" href="assets/poster.pdf" target="_blank"><span class="icon"><i class="fa-solid fa-image"></i></span><span>Poster</span></a>
        <a class="button is-primary is-light" href="assets/slides.pdf" target="_blank"><span class="icon"><i class="fa-solid fa-person-chalkboard"></i></span><span>Slides</span></a>
        <a class="button is-primary is-light" href="#bibtex"><span class="icon"><i class="fa-solid fa-quote-right"></i></span><span>BibTeX</span></a>
      </div>
    </div>
  </section> -->

  <section class="section">
    <div class="container">
      <h2 class="section-title">Paper</h2>
        <div class="content has-text-centered">
          <iframe src="assets/dejavu.pdf#view=FitH" style="width:100%; height:600px; border:1px solid #eee; border-radius: 8px;"></iframe>
          <p class="has-text-grey is-size-7" style="margin-top: .5rem;">If the preview does not load, use the PDF button above.</p>
        </div>
    </div>
  </section>


  <!-- Method -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Method Overview</h2>
      <div class="content">
        <p>
          An <strong>experience</strong> is defined as a synchronized trajectory of vision, language, and action. At each step, EFN retrieves a
          task‑filtered candidate from the bank using language‑conditioned visual similarity, then predicts a <em>residual action</em> that is
          added to the base VLA output. A dense semantic reward encourages the next observation to resemble the successor frame from
          the retrieved experience while regularizing residual magnitude and discouraging idling. We train EFN with <em>Soft Actor–Critic</em>
          (SAC) and deploy with deterministic residual corrections.
        </p>
      </div>
          <div class="box figure">
            <img src="assets/pipeline.png" alt="Training pipeline: retrieval + residual policy learning with similarity rewards.">
            <p class="has-text-grey is-size-9" style="margin-top:.5rem;">Training: retrieve, correct, and optimize with dense similarity rewards. Inference: instruction‑filtered retrieval and online experience growth.</p>
          </div>
    </div>
  </section>



  <!-- Results -->
<section class="section" id="demos">
  <div class="container">
    <h2 class="section-title">Demos (1 × speed)</h2>

    <div class="columns is-multiline">

      <!-- DrawerStore - with EFN -->
      <div class="column is-12">
        <div class="card">
          <header class="card-header">
            <p class="card-header-title">
              <span class="tag is-link is-light" style="margin-right:.5rem;">Task</span> DrawerStore · with EFN
            </p>
          </header>
          <div class="card-content">
            <p class="content">
              <strong>Description:</strong> Open the drawer with the left arm, pick up the napkin packet with the right arm, hand it to the left arm, and store it inside the drawer. This demo shows a smooth, decisive execution enabled by EFN.
            </p>
            <ol class="content" style="margin-top:-.5rem;">
              <li>Use the <em>left</em> arm to pull the drawer open beyond the minimum displacement.</li>
              <li>Grasp the napkin packet from the tabletop with the <em>right</em> arm.</li>
              <li>Transfer the packet from the right gripper to the <em>left</em> gripper.</li>
              <li>Place the packet into the drawer interior and open both grippers.</li>
            </ol>
            <video class="teaser auto-poster" preload="metadata" controls playsinline crossorigin="anonymous">
              <source src="assets/DrawerStore with EFN.mp4" type='video/mp4; codecs="avc1.64001f, mp4a.40.2"'>
              <!-- <source src="assets/DrawerStore with EFN.webm" type="video/webm"> -->
              Your browser does not support inline video.
              <a href="assets/DrawerStore with EFN.mp4" download>Download MP4</a>.
            </video>
          </div>
        </div>
      </div>

      <!-- DrawerStore - without EFN -->
      <div class="column is-12">
        <div class="card">
          <header class="card-header">
            <p class="card-header-title">
              <span class="tag is-link is-light" style="margin-right:.5rem;">Task</span> DrawerStore · without EFN
            </p>
          </header>
          <div class="card-content">
            <p class="content">
              <strong>Description:</strong> Paired comparison on the most challenging task. Even in a successful rollout, the baseline policy (without EFN) often exhibits hesitant behavior such as repeated grasps and an imprecise final release.
            </p>
            <ol class="content" style="margin-top:-.5rem;">
              <li>Use the <em>left</em> arm to pull the drawer open beyond the minimum displacement.</li>
              <li>Grasp the napkin packet from the tabletop with the <em>right</em> arm.</li>
              <li>Transfer the packet from the right gripper to the <em>left</em> gripper.</li>
              <li>Place the packet into the drawer interior and open both grippers.</li>
            </ol>
            <video class="teaser auto-poster" preload="metadata" controls playsinline crossorigin="anonymous">
              <source src="assets/DrawerStore without EFN.mp4" type='video/mp4; codecs="avc1.64001f, mp4a.40.2"'>
              <!-- <source src="assets/DrawerStore without EFN.webm" type="video/webm"> -->
              Your browser does not support inline video.
              <a href="assets/DrawerStore without EFN.mp4" download>Download MP4</a>.
            </video>
          </div>
        </div>
      </div>

      <!-- ShelfSort - with EFN -->
      <div class="column is-12">
        <div class="card">
          <header class="card-header">
            <p class="card-header-title">
              <span class="tag is-link is-light" style="margin-right:.5rem;">Task</span> ShelfSort · with EFN
            </p>
          </header>
          <div class="card-content">
            <p class="content">
              <strong>Description:</strong> Grasp a drink from the shelf with the right arm and place it into the designated cluster region next to visually similar items, then release the gripper.
            </p>
            <ol class="content" style="margin-top:-.5rem;">
              <li>Identify the target drink placed at a randomized start position on the shelf.</li>
              <li>Grasp the target drink with the <em>right</em> arm.</li>
              <li>Move to the cluster region and place it next to similar drinks (within a fixed 3D tolerance).</li>
              <li>Release the right-arm gripper at the end of the episode.</li>
            </ol>
            <video class="teaser auto-poster" preload="metadata" controls playsinline crossorigin="anonymous">
              <source src="assets/ShelfSort with EFN.mp4" type='video/mp4; codecs="avc1.64001f, mp4a.40.2"'>
              <!-- <source src="assets/ShelfSort with EFN.webm" type="video/webm"> -->
              Your browser does not support inline video.
              <a href="assets/ShelfSort with EFN.mp4" download>Download MP4</a>.
            </video>
          </div>
        </div>
      </div>

      <!-- StockLift - with EFN -->
      <div class="column is-12">
        <div class="card">
          <header class="card-header">
            <p class="card-header-title">
              <span class="tag is-link is-light" style="margin-right:.5rem;">Task</span> StockLift · with EFN
            </p>
          </header>
          <div class="card-content">
            <p class="content">
              <strong>Description:</strong> Pick up the top can from a vertical stack on a small table with the right arm and place it onto the shelf within the predefined goal region, then release.
            </p>
            <ol class="content" style="margin-top:-.5rem;">
              <li>Grasp the <em>top</em> can from the stack with the <em>right</em> arm.</li>
              <li>Lift the can cleanly without disturbing the remaining stack.</li>
              <li>Move to the shelf and place the can in the goal region.</li>
              <li>Open the right gripper to finish the task.</li>
            </ol>
            <video class="teaser auto-poster" preload="metadata" controls playsinline crossorigin="anonymous">
              <source src="assets/StockLift with EFN.mp4" type='video/mp4; codecs="avc1.64001f, mp4a.40.2"'>
              <!-- <source src="assets/StockLift with EFN.webm" type="video/webm"> -->
              Your browser does not support inline video.
              <a href="assets/StockLift with EFN.mp4" download>Download MP4</a>.
            </video>
          </div>
        </div>
      </div>

      <!-- BottlePlace - with EFN -->
      <div class="column is-12">
        <div class="card">
          <header class="card-header">
            <p class="card-header-title">
              <span class="tag is-link is-light" style="margin-right:.5rem;">Task</span> BottlePlace · with EFN
            </p>
          </header>
          <div class="card-content">
            <p class="content">
              <strong>Description:</strong> Pick up the plastic bottle from the tabletop with the right arm and place it into the open box that serves as the goal region, then open the gripper.
            </p>
            <ol class="content" style="margin-top:-.5rem;">
              <li>Grasp the bottle from the tabletop with the <em>right</em> arm.</li>
              <li>Lift and move toward the open box (goal region).</li>
              <li>Place the bottle inside the box (center lies within the predefined region).</li>
              <li>Release by fully opening the right-arm gripper.</li>
            </ol>
            <video class="teaser auto-poster" preload="metadata" controls playsinline crossorigin="anonymous">
              <source src="assets/BottlePlace with EFN.mp4" type='video/mp4; codecs="avc1.64001f, mp4a.40.2"'>
              <!-- <source src="assets/BottlePlace with EFN.webm" type="video/webm"> -->
              Your browser does not support inline video.
              <a href="assets/BottlePlace with EFN.mp4" download>Download MP4</a>.
            </video>
          </div>
        </div>
      </div>

    </div>
  </div>
</section>




  <!-- Citation -->
  <section class="section" id="bibtex">
    <div class="container">
      <h2 class="section-title">BibTeX</h2>
      <code class="bibtex">@article{wu2025dejavu,
  title={Dejavu: Towards Experience Feedback Learning for Embodied Intelligence},
  author={Wu, Shaokai and Ji, Yanbiao and Li, Qiuchang and Zhang, Zhiyi and He, Qichen and Xie, Wenyuan and Zhang, Guodong and Bayramli, Bayram and Ding, Yue and Lu, Hongtao},
  journal={arXiv preprint arXiv:2510.10181},
  year={2025}
}</code>
    </div>
  </section>

  <!-- Acknowledgements -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Acknowledgements</h2>
      <p class="content">
        This website follows the structure of the <em>nerfies.github.io</em> academic project template.
      </p>
    </div>
  </section>

  <footer class="footer">
    <div class="content has-text-centered">
      <p>
        <strong>Dejavu (EFN)</strong> — CVPR 2026 (under review). Site template inspired by <em>nerfies.github.io</em>.
      </p>
    </div>
  </footer>
</body>
</html>

